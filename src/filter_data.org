#+TITLE: Filtering the Data from the Aggregated Player Data
#+STARTUP: headlines
#+STARTUP: nohideblocks
#+STARTUP: noindent
#+OPTIONS: toc:4 h:4 ^:nil _:nil
#+PROPERTY: header-args:emacs-lisp :comments link
#+SETUPFILE: https://fniessen.github.io/org-html-themes/org/theme-readtheorg.setup
#+EXPORT_FILE_NAME: filter_data.html
#+HTML_HEAD: <style> #content{max-width:1800px;}</style>

* Activating Python Environment

  This code block must be run to activate python virtual environment for
  org session "SESSION_1". The following Python code blocks are run in
  "SESSION_1" in which the virtual environment should have been activated.

#+BEGIN_SRC emacs-lisp :session SESSION_1 :exports both
  (pyvenv-activate "~/gitRepos/TTK28-project/venv/")
#+END_SRC

#+RESULTS:

* Importing dependencies
  This filtering of data typically uses ~pandas~ and ~numpy~ for data storage
  and manipulation. Additionally a the Random function is used for picking out
  the data. The data is standardized using ~Sklearn~ and the ~StandardScalar~.

#+begin_src python :session SESSION_1 :results output :exports both
import pandas as pd
import numpy as np
from numpy.random import RandomState
from icecream import ic
from sklearn.preprocessing import StandardScaler, OneHotEncoder
#+end_src

#+RESULTS:

* Hyperparameters
  In order to more easily configure the model and keep track of the setting,
  this hyperparameters dictionary is defined here and used throughout the code
  where needed.

#+begin_src python :session SESSION_1 :results output :exports both
NAME = "full"
DATA_BALANCE_PERCENTAGE = 0.8
TRAINING_DATA_FRACTION = 0.8
#+end_src

#+RESULTS:

* Helper Function

   This function determines the number of samples to extract based on a
   percentage how imbalanced the dataset should be.

#+begin_src python :session SESSION_1 :results output :exports both
def num_sample(percentage, hof_df):
    hof_length = len(hof_df['G_all'])
    return int((percentage * hof_length)/(1 - percentage))
#+end_src

#+RESULTS:

* Importing and Cleaning the Data

#+begin_src python :session SESSION_1 :results output :exports both
df = pd.read_csv('../data/final_data.csv')
#+end_src

#+RESULTS:
: sys:1: DtypeWarning: Columns (48) have mixed types.Specify dtype option on import or set low_memory=False.

  Fixing Last Game Played date into a ~float32~.

#+begin_src python :session SESSION_1 :results output :exports both
# Splits the final Game date and convert to string
finalGameYear = df['finalGame'].str.split(pat="-", expand=True)[0]
df['finalGame'] = finalGameYear
# Removing NaN fields from the dataset
df = df[finalGameYear.notnull()]
# Adding back to dataset as ints
df['finalGame'] = df['finalGame'].astype('float32')
#+end_src

#+RESULTS:

  Fixing parts that cannot have NaN.

#+begin_src python :session SESSION_1 :results output :exports both
  # Replacing NaN in each column with 0 and adding back as type
  award_names = ['Most Valuable Player', 'World Series MVP', 'AS_games', 'Gold Glove',
                 'Rookie of the Year', 'Silver Slugger','G', 'AB', 'R', 'H', '2B', '3B',
                 'HR', 'RBI', 'SB', 'BB', 'SO', 'IBB', 'HBP', 'SH', 'SF', 'BB-A', 'H-A',
                 'IPouts', 'SO-A', 'BB-A', 'IBB-A', 'PO', 'A', 'E', 'DP']
  for col in award_names:
      df[col] = df[col].fillna(0)
      df[col] = df[col].astype('float32')
#+end_src

#+RESULTS:

* Creating Additional Statistics

  In order to aggregate the data into stats which are considered features/stats
  which express the skill of a batter. It would be possible to use all the
  features individually, but with a smaller and imbalanced dataset it would be
  nice not to have to include more features than necessary. These stats are 1B,
  SLG, OBS, OPS.

#+begin_src python :session SESSION_1 :results output :exports both
  # Adding the Batting Stats
  df['1B'] = df['H'] - df['2B'] - df['3B'] - df['HR']
  df['SLG'] = (df['1B'] + 2*df['2B'] + 3*df['3B'] + 4*df['HR'])/df['AB']
  df['OBS'] = (df['H'] + df['BB'] + df['HBP'])/(df['AB'] + df['BB']+ df['HBP']+ df['SF'])
  df['OPS'] = df['SLG'] + df['OBS']

  # Adding the Pitching Stats
  df['WHIP'] = round(3*(df['BB-A'] + df['H-A'])/df['IPouts'], 2)
  df['KperBB'] = round(df['SO-A']/(df['BB-A'] - df['IBB-A']), 2)

  new_stats = ['1B', 'SLG', 'OBS', 'OPS', 'WHIP', 'KperBB']
  for col in new_stats:
      df[col] = df[col].fillna(0)
      df[col] = df[col].astype('float32')
#+end_src

#+RESULTS:

#+begin_src python :session SESSION_1 :results output :exports both
stat_names = ['G', 'AB', 'R', 'H', '2B', '3B', 'HR', 'RBI', 'SB',
              'BB', 'SO', 'IBB', 'HBP', 'SH', 'SF', '1B', 'OPS', 'SLG', 'OBS', 'WHIP', 'KperBB']
for name in stat_names:
    string = 'number of NaN values in '+ name
#+end_src

#+RESULTS:

* Fulfilling criteria for HoF eligibility

  Removing players who have played less than 10 years as these players are not
  eligible for the MLB Hall of Fame.

#+begin_src python :session SESSION_1 :results output :exports both
  df = df[df['Years_Played'] >= 10] # 10 years
#+end_src

#+RESULTS:

* Preparing to Feed Data into Model

** Selecting Variables to use in training

#+begin_src python :session SESSION_1 :results output :exports both

  # Removing values with incompatible values
  # ic(df.shape)
  # ic(df['WHIP'] != inf)
  # ic(df['KperBB'] != inf)
  # ic(df_inf.shape)
  # ic(np.isinf(df))
  # ic(df_inf['WHIP'])
  # ic(df_inf['KperBB'])
  # df[np.isinf(df['KperBB'])]
  # ic(df.shape)
  # ic(df.max())
  # ic(df.groupby(np.isinf(df['WHIP'])).count())
  # ic(df.groupby(np.isinf(df['KperBB'])).count())

  # pre_std_df = df
  hof_label_df = df[['playerID', 'HoF']]
  df_inf_containing = df[['WHIP', 'KperBB']]
  df = df[['POS','G_all', 'finalGame', 'OPS', 'SB', 'HR',
           'Years_Played', 'Most Valuable Player', 'AS_games',
           'Gold Glove', 'Rookie of the Year', 'World Series MVP', 'Silver Slugger',
           'WHIP', 'ERA', 'KperBB', 'PO', 'A', 'E', 'DP']]

  ic(df)
  df_inf = np.isinf(df_inf_containing)
  ic(df_inf)
  df = df[~df_inf['WHIP']]
  df = df[~df_inf['KperBB']]
  hof_label_df = hof_label_df[~df_inf['WHIP']]
  hof_label_df = hof_label_df[~df_inf['KperBB']]

  # ic(pre_std_df.shape)
#+end_src

#+RESULTS:
#+begin_example
ic| df:       POS  G_all  finalGame       OPS     SB     HR  ...       ERA  KperBB       PO       A      E      DP
        3       C    316     1883.0  0.604969    0.0    2.0  ...  1.800000    0.00   1328.0   269.0  237.0    24.0
        4      1B   2524     1897.0  0.838926    0.0   97.0  ...  9.000000    0.50  22572.0  1612.0  976.0  1283.0
        11     OF    480     1890.0  0.521447    0.0    3.0  ...  3.580000    0.50    908.0  1253.0  367.0    88.0
        30      C    452     1884.0  0.592735    0.0    8.0  ...       NaN    0.00    820.0    63.0  173.0     6.0
        34     OF    575     1885.0  0.619459    0.0    0.0  ...       NaN    0.00   1209.0    90.0  148.0    19.0
        ...    ..    ...        ...       ...    ...    ...  ...       ...     ...      ...     ...    ...     ...
        17279  2B    937     2018.0  0.829678   32.0   93.0  ...       NaN    0.00    761.0  1390.0   67.0   177.0
        17286  3B   1173     2018.0  0.768319   29.0  141.0  ...       NaN    0.00   2279.0  2876.0   62.0   679.0
        17291   C   1081     2018.0  0.724818    8.0  135.0  ...       NaN    0.00   7225.0   412.0   56.0    72.0
        17293  2B    651     2018.0  0.643173  162.0   13.0  ...       NaN    0.00    768.0   141.0   17.0    33.0
        17295   P    254     2018.0  0.387644    0.0    1.0  ...  4.805488    3.85     97.0   185.0   13.0     7.0
        
        [3416 rows x 20 columns]
ic| df_inf:         WHIP  KperBB
            3      False   False
            4      False   False
            11     False   False
            30     False   False
            34     False   False
            ...      ...     ...
            17279  False   False
            17286  False   False
            17291  False   False
            17293  False   False
            17295  False   False
            
            [3416 rows x 2 columns]
/tmp/babel-aDvIBM/python-SxxO4C:28: UserWarning: Boolean Series key will be reindexed to match DataFrame index.
  df = df[~df_inf['KperBB']]
/tmp/babel-aDvIBM/python-SxxO4C:30: UserWarning: Boolean Series key will be reindexed to match DataFrame index.
  hof_label_df = hof_label_df[~df_inf['KperBB']]
#+end_example


** One Hot Encoding for Player Position Data

#+begin_src python :session SESSION_1 :results output :exports both
  ic("in One Hot Encoding")
  # creating one hot encoder object 
  onehotencoder = OneHotEncoder()
  #reshape the 1-D country array to 2-D as fit_transform expects 2-D and finally fit the object 
  # X = onehotencoder.fit_transform(df.POS.values.reshape(-1,1)).toarray()
  X = onehotencoder.fit_transform(df[['POS']]).toarray()

  # X = onehotencoder.fit_transform(df.POS.reshape(-1,1)).toarray()
  #To add this back into the original dataframe 
  ic(df)
  ic(df.POS.value_counts())
  ic(X)
  ic(X.shape)
  ic(df.shape)
  dfOneHot = pd.DataFrame(X, columns = ["POS_"+str(int(i)) for i in range(X.shape[1])]) 
  ic(dfOneHot)
  # df = pd.concat([df, dfOneHot], axis=1)
  df = df.join(dfOneHot)
  ic(df)
  #droping the country column 
  df= df.drop(['POS'], axis=1) 
  ic(df)
  #printing to verify 
  print(df.head())
#+end_src

 #+RESULTS:
 #+begin_example
 ic| 'in One Hot Encoding'
 ic| df:       POS  G_all  finalGame       OPS     SB     HR  ...       ERA  KperBB       PO       A      E      DP
         3       C    316     1883.0  0.604969    0.0    2.0  ...  1.800000    0.00   1328.0   269.0  237.0    24.0
         4      1B   2524     1897.0  0.838926    0.0   97.0  ...  9.000000    0.50  22572.0  1612.0  976.0  1283.0
         11     OF    480     1890.0  0.521447    0.0    3.0  ...  3.580000    0.50    908.0  1253.0  367.0    88.0
         30      C    452     1884.0  0.592735    0.0    8.0  ...       NaN    0.00    820.0    63.0  173.0     6.0
         34     OF    575     1885.0  0.619459    0.0    0.0  ...       NaN    0.00   1209.0    90.0  148.0    19.0
         ...    ..    ...        ...       ...    ...    ...  ...       ...     ...      ...     ...    ...     ...
         17279  2B    937     2018.0  0.829678   32.0   93.0  ...       NaN    0.00    761.0  1390.0   67.0   177.0
         17286  3B   1173     2018.0  0.768319   29.0  141.0  ...       NaN    0.00   2279.0  2876.0   62.0   679.0
         17291   C   1081     2018.0  0.724818    8.0  135.0  ...       NaN    0.00   7225.0   412.0   56.0    72.0
         17293  2B    651     2018.0  0.643173  162.0   13.0  ...       NaN    0.00    768.0   141.0   17.0    33.0
         17295   P    254     2018.0  0.387644    0.0    1.0  ...  4.805488    3.85     97.0   185.0   13.0     7.0

         [3396 rows x 20 columns]
 ic| df.POS.value_counts(): P     1268
                            OF     667
                            2B     389
                            C      365
                            1B     289
                            3B     238
                            SS     180
                            Name: POS, dtype: int64
 ic| X: array([[0., 0., 0., ..., 0., 0., 0.],
               [1., 0., 0., ..., 0., 0., 0.],
               [0., 0., 0., ..., 1., 0., 0.],
               ...,
               [0., 0., 0., ..., 0., 0., 0.],
               [0., 1., 0., ..., 0., 0., 0.],
               [0., 0., 0., ..., 0., 1., 0.]])
 ic| X.shape: (3396, 7)
 ic| df.shape: (3396, 20)
 ic| dfOneHot:       POS_0  POS_1  POS_2  POS_3  POS_4  POS_5  POS_6
               0       0.0    0.0    0.0    1.0    0.0    0.0    0.0
               1       1.0    0.0    0.0    0.0    0.0    0.0    0.0
               2       0.0    0.0    0.0    0.0    1.0    0.0    0.0
               3       0.0    0.0    0.0    1.0    0.0    0.0    0.0
               4       0.0    0.0    0.0    0.0    1.0    0.0    0.0
               ...     ...    ...    ...    ...    ...    ...    ...
               3391    0.0    1.0    0.0    0.0    0.0    0.0    0.0
               3392    0.0    0.0    1.0    0.0    0.0    0.0    0.0
               3393    0.0    0.0    0.0    1.0    0.0    0.0    0.0
               3394    0.0    1.0    0.0    0.0    0.0    0.0    0.0
               3395    0.0    0.0    0.0    0.0    0.0    1.0    0.0

               [3396 rows x 7 columns]
 ic| df:       POS  G_all  finalGame       OPS     SB     HR  ...  POS_1  POS_2  POS_3  POS_4  POS_5  POS_6
         3       C    316     1883.0  0.604969    0.0    2.0  ...    0.0    0.0    1.0    0.0    0.0    0.0
         4      1B   2524     1897.0  0.838926    0.0   97.0  ...    0.0    0.0    0.0    1.0    0.0    0.0
         11     OF    480     1890.0  0.521447    0.0    3.0  ...    1.0    0.0    0.0    0.0    0.0    0.0
         30      C    452     1884.0  0.592735    0.0    8.0  ...    0.0    0.0    1.0    0.0    0.0    0.0
         34     OF    575     1885.0  0.619459    0.0    0.0  ...    0.0    0.0    0.0    1.0    0.0    0.0
         ...    ..    ...        ...       ...    ...    ...  ...    ...    ...    ...    ...    ...    ...
         17279  2B    937     2018.0  0.829678   32.0   93.0  ...    NaN    NaN    NaN    NaN    NaN    NaN
         17286  3B   1173     2018.0  0.768319   29.0  141.0  ...    NaN    NaN    NaN    NaN    NaN    NaN
         17291   C   1081     2018.0  0.724818    8.0  135.0  ...    NaN    NaN    NaN    NaN    NaN    NaN
         17293  2B    651     2018.0  0.643173  162.0   13.0  ...    NaN    NaN    NaN    NaN    NaN    NaN
         17295   P    254     2018.0  0.387644    0.0    1.0  ...    NaN    NaN    NaN    NaN    NaN    NaN

         [3396 rows x 27 columns]
 ic| df:        G_all  finalGame       OPS     SB     HR  ...  POS_2  POS_3  POS_4  POS_5  POS_6
         3        316     1883.0  0.604969    0.0    2.0  ...    0.0    1.0    0.0    0.0    0.0
         4       2524     1897.0  0.838926    0.0   97.0  ...    0.0    0.0    1.0    0.0    0.0
         11       480     1890.0  0.521447    0.0    3.0  ...    0.0    0.0    0.0    0.0    0.0
         30       452     1884.0  0.592735    0.0    8.0  ...    0.0    1.0    0.0    0.0    0.0
         34       575     1885.0  0.619459    0.0    0.0  ...    0.0    0.0    1.0    0.0    0.0
         ...      ...        ...       ...    ...    ...  ...    ...    ...    ...    ...    ...
         17279    937     2018.0  0.829678   32.0   93.0  ...    NaN    NaN    NaN    NaN    NaN
         17286   1173     2018.0  0.768319   29.0  141.0  ...    NaN    NaN    NaN    NaN    NaN
         17291   1081     2018.0  0.724818    8.0  135.0  ...    NaN    NaN    NaN    NaN    NaN
         17293    651     2018.0  0.643173  162.0   13.0  ...    NaN    NaN    NaN    NaN    NaN
         17295    254     2018.0  0.387644    0.0    1.0  ...    NaN    NaN    NaN    NaN    NaN

         [3396 rows x 26 columns]
     G_all  finalGame       OPS   SB    HR  Years_Played  ...  POS_1  POS_2  POS_3  POS_4  POS_5  POS_6
 3     316     1883.0  0.604969  0.0   2.0          10.0  ...    0.0    0.0    1.0    0.0    0.0    0.0
 4    2524     1897.0  0.838926  0.0  97.0          27.0  ...    0.0    0.0    0.0    1.0    0.0    0.0
 11    480     1890.0  0.521447  0.0   3.0          10.0  ...    1.0    0.0    0.0    0.0    0.0    0.0
 30    452     1884.0  0.592735  0.0   8.0          10.0  ...    0.0    0.0    1.0    0.0    0.0    0.0
 34    575     1885.0  0.619459  0.0   0.0          11.0  ...    0.0    0.0    0.0    1.0    0.0    0.0

 [5 rows x 26 columns]
 #+end_example

** Standardizing the Data

#+begin_src python :session SESSION_1 :results output :exports both
  # df[np.isinf(df['WHIP']) or np.isinf(df['KperBB'])]
  # ic(np.isinf(df['WHIP']))
  # ic(np.isinf(df['KperBB']))
  # df[np.isinf(df['WHIP'])]
  # df[np.isinf(df['KperBB'])]
  # ic(df.max())
  ic("in standardizing the data")
  df = pd.DataFrame(StandardScaler().fit_transform(df), columns=df.columns)
  ### Adding back the HoF data
  ic("right after standardizing the data")
  df.insert(df.shape[1], 'HoF', hof_label_df['HoF'].to_numpy())
#+end_src

 #+RESULTS:
 : ic| 'in standardizing the data'
 : ic| 'right after standardizing the data'

** Converting HoF back to strings

#+begin_src python :session SESSION_1 :results output :exports both
 ic("in Converting HoF back to string")
 df['HoF'] = df['HoF'].replace(1.0, 'Y', regex=True)
 df['HoF'] = df['HoF'].replace(np.nan, 'N', regex=True)
 df['HoF'] = df['HoF'].replace(0.0, 'N', regex=True)
#+end_src

 #+RESULTS:
 : ic| 'in Converting HoF back to string'

** Splitting dataset by HoF players

 #+begin_src python :session SESSION_1 :results output :exports both
reg_df = df[df['HoF'] == 'N']
hof_df = df[df['HoF'] == 'Y']
 #+end_src

 #+RESULTS:

** Under-sampling the non-HoF players

   Currently, the non-HoF players are not undersampled.

 #+begin_src python :session SESSION_1 :results output :exports both
reg_seeded_random = RandomState(1)
# sampled_reg_df = reg_df.sample(n = num_sample(DATA_BALANCE_PERCENTAGE, hof_df), random_state=reg_seeded_random)
sampled_reg_df = reg_df
 #+end_src

 #+RESULTS:

** Splitting reg and HoF into train and test

 #+begin_src python :session SESSION_1 :results output :exports both
sep_seeded_random = RandomState(1)
train_reg_df = sampled_reg_df.sample(frac=TRAINING_DATA_FRACTION, random_state=sep_seeded_random)
test_reg_df = sampled_reg_df.drop(train_reg_df.index)
train_hof_df = hof_df.sample(frac=TRAINING_DATA_FRACTION, random_state=sep_seeded_random)
test_hof_df = hof_df.drop(train_hof_df.index)

print('length of train_reg_df: ', len(train_reg_df))
print('length of test_reg_df: ', len(test_reg_df))
print('length of train_hof_df: ', len(train_hof_df))
print('length of test_hof_df: ', len(test_hof_df))
 #+end_src

 #+RESULTS:
 : length of train_reg_df:  2537
 : length of test_reg_df:  634
 : length of train_hof_df:  180
 : length of test_hof_df:  45

** Merging the test and training datasets

 #+begin_src python :session SESSION_1 :results output :exports both
train_df = pd.concat([train_hof_df, train_reg_df])
test_df = pd.concat([test_hof_df, test_reg_df])
# Shuffling the data
train_df = train_df.sample(frac = 1, random_state=sep_seeded_random)
test_df = test_df.sample(frac = 1, random_state=sep_seeded_random)
 #+end_src

 #+RESULTS:

* Save the different testing and validation data sets

 #+begin_src python :session SESSION_1 :results output :exports both
train_df.to_csv('../data/train_data_' + NAME + '.csv', index=False)
test_df.to_csv('../data/test_data_' + NAME + '.csv', index=False)
 #+end_src

 #+RESULTS:

* Links to Other Files in Project

  1. [[https://www.olavpedersen.com/standalone_hof/extract_data.html][extract_data]]: Extracting data from Lahman's raw data.
  2. [[https://www.olavpedersen.com/standalone_hof/filter_data.html][filter_data]]: Data manipulation, feature creation and feature selection.
  3. [[https://www.olavpedersen.com/standalone_hof/hall_of_fame_model.html][hof_model]]: Creation of the model and training of the neural network.


* Local Variables                                          :noexport:ARCHIVE:
# Local Variables:
# after-save-hook: org-html-export-to-html
# End:
