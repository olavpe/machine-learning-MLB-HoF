#+TITLE: Grid Search Results
#+STARTUP: headlines
#+STARTUP: nohideblocks
#+STARTUP: noindent
#+OPTIONS: toc:4 h:4 ^:nil _:nil
#+PROPERTY: header-args:emacs-lisp :comments link
#+SETUPFILE: https://fniessen.github.io/org-html-themes/org/theme-readtheorg.setup
#+EXPORT_FILE_NAME: grid_search_results.html
#+HTML_HEAD: <style> #content{max-width:1800px;}</style>


* Decision Tree

    The following results are from when only using the original 10 features.
    The following pipeline also uses Principal Component Analysis (PCA) first
    and finds the best number of components for the decision tree.

    *PCA Components*:
    - Best number of components: From 1 to the max number of features (10).

    *Decision Tree*:
    - Different Class Weights ~class_weight=[{0: 1.0, 1: w} for w in [10, 12, 14, 15, 16, 17, 18]],~
    - Criterion = ~['gini', 'entropy']~
    - Max Depth = ~[2, 4, 6, 8, 10, 12]~

#+begin_example
 : Best Score: 0.5178250609559948
 : Best Criterion: gini
 : Best max_depth: 12
 : Best Number Of Components: 6
 :
 : DecisionTreeClassifier(class_weight={0: 1.0, 1: 16}, max_depth=12)
#+end_example

* Logistic Regression

     The following results are from when only using the original 10 features.

     - Penalty = ~['l1', 'l2']~
     - C = ~np.logspace(-4, 4, 20),~
     - Different Class Weights ~class_weight=[{0: 1.0, 1: w} for w in [10, 12, 14, 15, 16, 17, 18]],~
     - Solver = ~['liblinear']~

 #+begin_example
Fitting 5 folds for each of 280 candidates, totalling 1400 fits
Best Score: 0.5373897826007131

Best Estimator: LogisticRegression(C=1.623776739188721, class_weight={0: 1.0, 1: 10},
                   penalty='l1', random_state=0, solver='liblinear')
 #+end_example

* Neural Network
  
** For the original 10 input features

    The following results are from when only using the original 10 features.
    There were a few iterations since the optimal solutions were endpoints.

    The dataset for this was not balanced! There were no class weights for the
    following result
    - Batch Size = ~[2, 4, 6, 8, 10]~
    - Epochs = ~[100, 125, 150, 175, 200]~

#+begin_example
Best Score: 0.6292982089131982
Best Estimator: {'verbose': 0, 'batch_size': 4, 'epochs': 200, 'build_fn': <function create_model at 0x7f440e43d9d0>}
#+end_example

    The ~class weights~ parameter were set to 'balanced' for this run.
    - Batch Size = ~[3, 4, 5]~
    - Epochs = ~[190, 200, 210]~

#+begin_example
Best Score: 0.589460143563261

Best Estimator: {'verbose': 0, 'batch_size': 5, 'epochs': 210, 'build_fn': <function create_model at 0x7f938bf6a9d0>}
#+end_example

    The ~class weights~ parameter were set to 'balanced' for this run.
    - Batch Size = ~[4, 6, 10, 20]~
    - Epochs = ~[200, 250, 300, 400]~

#+begin_example
Best Score: 0.5824397099036812
Best Estimator: {'verbose': 0, 'batch_size': 6, 'epochs': 250, 'build_fn': <function create_model at 0x7f938bf5a280>}
#+end_example

** For the added 26 input features with 26-13-1 structure

    The ~class weights~ parameter were set to 'balanced' for this run.
    - Batch Size = ~[5, 6, 7]~
    - Epochs = ~[230, 235, 240, 245, 250]~

#+begin_example
Best Score: 0.6141709069236523

Best Estimator: {'verbose': 0, 'batch_size': 6, 'epochs': 240, 'build_fn': <function create_model at 0x7fe6b47933a0>}
#+end_example

** For the added 26 input features with 26-17-9-1 structure

    The ~class weights~ parameter were set to 'balanced' for this run.
    - Batch Size = ~[2, 4, 6, 8, 10]~
    - Epochs = ~[100, 125, 150, 175, 200]~

#+begin_example
Best Score: 0.6292286798742979

Best Estimator: {'verbose': 0, 'batch_size': 2, 'epochs': 100, 'build_fn': <function create_model at 0x7fe6b4648670>}
#+end_example

    The ~class weights~ parameter were set to 'balanced' for this run.
    - Batch Size = ~[1, 2, 4]~
    - Epochs = ~[25, 50, 75, 100, 125]~

#+begin_example
Best Score: 0.5979329942840022

Best Estimator: {'verbose': 0, 'batch_size': 1, 'epochs': 125, 'build_fn': <function create_model at 0x7fe634937040>}
#+end_example

    The ~class weights~ parameter were set to 'balanced' for this run.
    - Batch Size = ~[1, 2, 4]~
    - Epochs = ~[125, 150, 200, 250, 300]~

#+begin_example
Best Score: 0.6079706322981303

Best Estimator: {'verbose': 0, 'batch_size': 4, 'epochs': 125, 'build_fn': <function create_model at 0x7fe6b47933a0>}
#+end_example

It turns out that for this structure, it seems to be peaking at around 0.60 -
0.63 with:

 - Batch Size: 4
 - Epochs: 125

   
* Links to Other Files in Project

  1. [[https://www.olavpedersen.com/standalone_hof/extract_data.html][extract_data]]: Extracting data from Lahman's raw data.
  2. [[https://www.olavpedersen.com/standalone_hof/filter_data.html][filter_data]]: Data manipulation, feature creation and feature selection.
  3. [[https://www.olavpedersen.com/standalone_hof/hall_of_fame_model.html][hof_model]]: Creation of the model and training of the neural network.
  4. [[https://www.olavpedersen.com/standalone_hof/grid_search_results.html][grid_search_results]]: Storing some of the results for the best Grid Searches

* Local Variables                                          :noexport:ARCHIVE:
# Local Variables:
# after-save-hook: org-html-export-to-html
# End:
